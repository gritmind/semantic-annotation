{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Total feature length = 10121\n"
     ]
    }
   ],
   "source": [
    "# Choose what you want to use among various kinds of features\n",
    "using_1type = 1\n",
    "using_2type = 1\n",
    "using_3type = 1\n",
    "using_4type = 1\n",
    "\n",
    "##############################################################################################\n",
    "import numpy as np\n",
    "from matplotlib import pyplot \n",
    "import pandas as pd\n",
    "from pandas import read_csv \n",
    "from pandas import set_option \n",
    "from pandas.tools.plotting import scatter_matrix \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import PassiveAggressiveClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from data_handler import *\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "feature_path = 'assets/feature-vec/'\n",
    "tempdata_path = 'assets/temp-data/'\n",
    "\n",
    "### Data Load\n",
    "FE_X_train = load(feature_path+'FE_X_train')\n",
    "FE_X_test = load(feature_path+'FE_X_test')\n",
    "################################### FE\n",
    "FE2_X_train = load(feature_path+'FE2_X_train')\n",
    "FE2_X_test = load(feature_path+'FE2_X_test')\n",
    "################################### FE 2\n",
    "FE3_X_train = load(feature_path+'FE3_X_train')\n",
    "FE3_X_test = load(feature_path+'FE3_X_test')\n",
    "################################### FE 3\n",
    "FE4_X_train = load(feature_path+'FE4_X_train')\n",
    "FE4_X_test = load(feature_path+'FE4_X_test')\n",
    "#Y_train = load('pre_Y_train')\n",
    "#Y_test = load('pre_Y_test')\n",
    "Y_train = load(tempdata_path+'Ytrain')\n",
    "Y_test = load(tempdata_path+'Ytest')\n",
    "################################### Y\n",
    "feature_info_without_LK = load('feature_info_without_LK')\n",
    "\n",
    "### Choice Feature Set \n",
    "X_train, X_test = choice_feature_set(using_1type, using_2type, using_3type, using_4type,\\\n",
    "                                     FE_X_train, FE2_X_train, FE3_X_train, FE4_X_train,\\\n",
    "                                     FE_X_test, FE2_X_test, FE3_X_test, FE4_X_test)\n",
    "print('===> Total feature length =', len(X_train[0][0]))\n",
    "\n",
    "### SHOW FEATURE INFORMATION\n",
    "# for row in feature_info_without_LK:\n",
    "#     print(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "\"\"\" Remove unnecessary words \"\"\"\n",
    "################################\n",
    "#pre_X_train = load('pre_X_train') # preprocessed text data\n",
    "#pre_X_test = load('pre_X_test') # preprocessed text data\n",
    "\n",
    "# delete_list = ['the', ',', 'a', 'to']\n",
    "# X_train, Y_train = del_ele_in_li(delete_list, X_train, Y_train, for_X=True, one_dim=False)\n",
    "# X_test, Y_test = del_ele_in_li(delete_list, X_test, Y_test, for_X=True, one_dim=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "\"\"\" Unfold Data (from sequence to non-sequence) \"\"\"\n",
    "###################################################\n",
    "unfolded_X_train, unfolded_Y_train = unfold_data(X_train, Y_train)\n",
    "unfolded_X_test, unfolded_Y_test = unfold_data(X_test, Y_test)\n",
    "\n",
    "\n",
    "assert(len(X_train) == len(Y_train))\n",
    "assert(len(unfolded_X_train) == len(unfolded_Y_train))\n",
    "assert(len(unfolded_X_train[0]) == len(unfolded_X_test[0]))\n",
    "assert(len(X_test) == len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Feature Extraction with Univariate Statistical Tests (Chi-squared for classification) \n",
    "# from pandas import read_csv \n",
    "# from numpy import set_printoptions \n",
    "# from sklearn.feature_selection import SelectKBest \n",
    "# from sklearn.feature_selection import chi2 \n",
    "\n",
    "\n",
    "\n",
    "# test = SelectKBest(score_func=chi2, k=1000) \n",
    "# fit = test.fit(unfolded_X_train, unfolded_Y_train) \n",
    "\n",
    "# X_train_uni = fit.transform(unfolded_X_train)\n",
    "# X_test_uni = fit.transform(unfolded_X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=1000) \n",
    "# fit = pca.fit(unfolded_X_train)\n",
    "\n",
    "# X_train_pca = pca.transform(unfolded_X_train)\n",
    "# X_test_pca = pca.transform(unfolded_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Grid Search for Algorithm Tuning \n",
    "# from sklearn.model_selection import GridSearchCV \n",
    "# n_estimators = np.array([10, 50, 100, 300]) \n",
    "# param_grid = dict(n_estimators=n_estimators) \n",
    "# model = RandomForestClassifier() \n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid) # default 3-fold cross validation\n",
    "# grid.fit(unfolded_X_train, unfolded_Y_train) \n",
    "# print(grid.best_score_) \n",
    "# print(grid.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2553, 10121)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(unfolded_X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn ML Models\n",
    "\n",
    "* LR 중 LASSO LR이 더 효과있으리라 생각이 된다. 우리의 feature는 0이 매우 많은 sparse한 feature이기 때문이다.\n",
    "* LR 중 stepwise LR도 있다.\n",
    "* data set이 적을 때, cross-validation으로 모델 검증을 해도 된다. (development set없이) 하지만, 그럴려면, 코딩이 더 필요한데, 사전을 오로지 training data만 보고 구축해야 되기 때문이다. 따라서, scikit-learn에서 제공해주는 cross-validation함수를 사용하면 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= < SVM > =======================\n",
      "0.768115942029\n",
      "[[ 75   0   0   0   1   0   0   0  12   0   0   0   0   0   0   0   4]\n",
      " [  3   6   1   6   2   0   0   0   2   4   0   0   0   0   0   0   6]\n",
      " [  1   0 145   3   0   2   1   0   7   0   0   0   0   0   0   0   4]\n",
      " [  2   0   6 215   6   0   3   0  17  61   1   0   0   0   0   0  26]\n",
      " [  1   0   2  28 103   0   2   0   6   8   0   5   0   0   0   0   7]\n",
      " [  0   0   7   0   0 197   0   0   1   0   1   0   0   0   0   0   5]\n",
      " [  0   0   1   8   4   1 114   0   0   4   3   0   0   1   1   0   7]\n",
      " [  2   0   0   0   0   1   0 139   0   0   0   0   0   0   0   0   0]\n",
      " [  8   0   1  24   1   0   3   0 217  12   1   0   0   0   5   0   9]\n",
      " [  0   2   1  56   1   0   6   0   8 158   2   1   1   0   1   0  12]\n",
      " [  0   0   4   1   0   0   0   0   0   2  11   0   0   0   0   0   0]\n",
      " [  0   0   0   7   0   0   0   0   1  12   0  32   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   1]\n",
      " [  0   0   0   2   0   0   0   0   6   3   0   0   0   0  19   0   0]\n",
      " [  0   0   0   9   0   0   0   0   0  46   0   0   0   0   0   5   3]\n",
      " [  0   1   5  14   5   2   0   1  11   7   1   0   1   0   3   0 507]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82        92\n",
      "          1       0.67      0.20      0.31        30\n",
      "          2       0.84      0.89      0.86       163\n",
      "          3       0.58      0.64      0.61       337\n",
      "          4       0.84      0.64      0.72       162\n",
      "          5       0.97      0.93      0.95       211\n",
      "          6       0.88      0.79      0.83       144\n",
      "          7       0.99      0.98      0.99       142\n",
      "          8       0.75      0.77      0.76       281\n",
      "          9       0.50      0.63      0.56       249\n",
      "         10       0.55      0.61      0.58        18\n",
      "         11       0.84      0.60      0.70        53\n",
      "         12       0.78      0.88      0.82         8\n",
      "         13       0.92      0.92      0.92        12\n",
      "         14       0.66      0.63      0.64        30\n",
      "         15       1.00      0.08      0.15        63\n",
      "         16       0.86      0.91      0.88       558\n",
      "\n",
      "avg / total       0.78      0.77      0.76      2553\n",
      "\n",
      "micro =>  0.768115942029 \t 0.768115942029 \t 0.768115942029 \t None\n",
      "macro =>  0.789652927805 \t 0.70102316912 \t 0.711789435855 \t None\n",
      "weighted =>  0.784048659585 \t 0.768115942029 \t 0.762222983809 \t None\n",
      "\n",
      "\n",
      "======================= < SVM > =======================\n",
      "0.759498629064\n",
      "[[ 76   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   4]\n",
      " [  3   6   0   6   3   0   0   0   1   4   0   0   0   0   0   0   7]\n",
      " [  1   0 144   4   0   2   2   0   6   0   0   0   0   0   0   0   4]\n",
      " [  2   0   4 204   6   0   2   0  20  70   1   0   0   0   0   0  28]\n",
      " [  1   0   1  26 103   0   3   0   7  10   0   5   0   0   0   0   6]\n",
      " [  0   0   7   0   0 196   0   0   2   0   1   0   0   0   0   0   5]\n",
      " [  0   0   2   8   3   1 115   0   0   4   2   0   0   1   1   0   7]\n",
      " [  2   0   0   0   0   0   0 139   0   0   0   0   0   0   0   0   1]\n",
      " [  7   0   2  25   2   0   3   0 214  14   0   0   0   0   1   0  13]\n",
      " [  0   2   1  51   1   0   6   0   9 159   2   1   1   0   1   0  15]\n",
      " [  0   0   4   1   0   0   0   0   0   2  11   0   0   0   0   0   0]\n",
      " [  0   0   0  12   1   0   0   0   1   9   0  28   0   0   0   0   2]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   1]\n",
      " [  0   0   0   2   0   0   0   0   6   4   0   0   0   0  18   0   0]\n",
      " [  0   0   0   6   0   0   0   0   1  51   0   1   0   0   0   2   2]\n",
      " [  0   2   5  17   5   1   0   1  10   7   1   0   1   0   2   0 506]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        92\n",
      "          1       0.60      0.20      0.30        30\n",
      "          2       0.85      0.88      0.86       163\n",
      "          3       0.56      0.61      0.58       337\n",
      "          4       0.83      0.64      0.72       162\n",
      "          5       0.98      0.93      0.95       211\n",
      "          6       0.87      0.80      0.83       144\n",
      "          7       0.99      0.98      0.99       142\n",
      "          8       0.74      0.76      0.75       281\n",
      "          9       0.48      0.64      0.55       249\n",
      "         10       0.61      0.61      0.61        18\n",
      "         11       0.80      0.53      0.64        53\n",
      "         12       0.78      0.88      0.82         8\n",
      "         13       0.92      0.92      0.92        12\n",
      "         14       0.78      0.60      0.68        30\n",
      "         15       1.00      0.03      0.06        63\n",
      "         16       0.84      0.91      0.87       558\n",
      "\n",
      "avg / total       0.78      0.76      0.75      2553\n",
      "\n",
      "micro =>  0.759498629064 \t 0.759498629064 \t 0.759498629064 \t None\n",
      "macro =>  0.791648401056 \t 0.689812726074 \t 0.703870328604 \t None\n",
      "weighted =>  0.776841561735 \t 0.759498629064 \t 0.752528433376 \t None\n",
      "\n",
      "\n",
      "======================= < SVM > =======================\n",
      "0.748531139835\n",
      "[[ 76   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   4]\n",
      " [  3   6   0   7   3   0   0   0   1   4   0   0   0   0   0   0   6]\n",
      " [  1   0 143   5   0   3   2   0   5   0   0   0   0   0   0   0   4]\n",
      " [  0   0   5 205   6   0   0   0  16  74   1   0   0   0   0   0  30]\n",
      " [  1   0   1  30 101   0   3   0   6  10   0   3   0   0   0   0   7]\n",
      " [  2   0   6   0   0 196   0   0   2   0   1   0   0   0   0   0   4]\n",
      " [  0   0   2   7   5   1 110   0   1   1   2   0   0   1   2   0  12]\n",
      " [  4   0   0   0   0   0   0 137   0   0   0   0   0   0   0   0   1]\n",
      " [  8   0   2  26   1   0   1   0 218  15   0   0   0   0   0   0  10]\n",
      " [  1   2   2  48   0   0   7   0  10 162   1   0   0   0   0   0  16]\n",
      " [  0   0   7   1   0   0   0   0   0   2   8   0   0   0   0   0   0]\n",
      " [  0   0   0  18   1   0   0   0   1  11   0  20   0   0   0   0   2]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   1]\n",
      " [  0   0   0   2   0   0   0   0   7   5   0   0   0   0  14   0   2]\n",
      " [  0   0   0   6   0   0   0   0   1  53   0   0   0   0   0   1   2]\n",
      " [  0   2   6  23   5   3   0   1  13   8   0   0   0   0   1   0 496]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81        92\n",
      "          1       0.60      0.20      0.30        30\n",
      "          2       0.82      0.88      0.85       163\n",
      "          3       0.54      0.61      0.57       337\n",
      "          4       0.83      0.62      0.71       162\n",
      "          5       0.97      0.93      0.95       211\n",
      "          6       0.89      0.76      0.82       144\n",
      "          7       0.99      0.96      0.98       142\n",
      "          8       0.74      0.78      0.76       281\n",
      "          9       0.47      0.65      0.55       249\n",
      "         10       0.62      0.44      0.52        18\n",
      "         11       0.87      0.38      0.53        53\n",
      "         12       1.00      0.88      0.93         8\n",
      "         13       0.92      0.92      0.92        12\n",
      "         14       0.82      0.47      0.60        30\n",
      "         15       1.00      0.02      0.03        63\n",
      "         16       0.83      0.89      0.86       558\n",
      "\n",
      "avg / total       0.77      0.75      0.74      2553\n",
      "\n",
      "micro =>  0.748531139835 \t 0.748531139835 \t 0.748531139835 \t None\n",
      "macro =>  0.805801734326 \t 0.659061284345 \t 0.686561573445 \t None\n",
      "weighted =>  0.770689643206 \t 0.748531139835 \t 0.740753788909 \t None\n",
      "\n",
      "\n",
      "======================= < SVM > =======================\n",
      "0.726204465335\n",
      "[[ 76   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   4]\n",
      " [  3   7   0   6   4   0   0   0   1   2   0   0   0   0   0   0   7]\n",
      " [  1   0 138   5   0   5   1   0   9   0   0   0   0   0   0   0   4]\n",
      " [  0   0   5 199  10   0   0   0  18  69   1   0   0   0   0   0  35]\n",
      " [  1   0   2  34  98   0   1   0   6   9   0   0   0   0   0   0  11]\n",
      " [  1   0   7   0   0 192   0   1   3   0   0   0   0   0   0   0   7]\n",
      " [  0   0   4   7   8   1 108   0   2   0   0   0   0   1   0   0  13]\n",
      " [  6   0   0   0   0   0   0 135   0   0   0   0   0   0   0   0   1]\n",
      " [  8   0   5  23   0   0   1   0 213  20   0   0   0   0   0   0  11]\n",
      " [  1   1   2  54   0   0   6   0   9 158   0   0   0   0   0   0  18]\n",
      " [  0   0   7   0   0   0   0   0   0   2   8   0   0   0   0   0   1]\n",
      " [  0   0   0  39   1   0   0   0   1  11   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  11   0   0   1]\n",
      " [  0   0   0   2   0   0   0   0  15   6   0   0   0   0   5   0   2]\n",
      " [  0   0   0   5   0   0   0   0   2  54   0   0   0   0   0   0   2]\n",
      " [  0   2   6  20   4   2   0   1  15   9   0   0   0   0   0   0 499]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.83      0.80        92\n",
      "          1       0.70      0.23      0.35        30\n",
      "          2       0.78      0.85      0.81       163\n",
      "          3       0.51      0.59      0.54       337\n",
      "          4       0.78      0.60      0.68       162\n",
      "          5       0.96      0.91      0.93       211\n",
      "          6       0.92      0.75      0.83       144\n",
      "          7       0.99      0.95      0.97       142\n",
      "          8       0.70      0.76      0.73       281\n",
      "          9       0.46      0.63      0.54       249\n",
      "         10       0.89      0.44      0.59        18\n",
      "         11       0.00      0.00      0.00        53\n",
      "         12       1.00      0.88      0.93         8\n",
      "         13       0.92      0.92      0.92        12\n",
      "         14       1.00      0.17      0.29        30\n",
      "         15       0.00      0.00      0.00        63\n",
      "         16       0.81      0.89      0.85       558\n",
      "\n",
      "avg / total       0.71      0.73      0.71      2553\n",
      "\n",
      "micro =>  0.726204465335 \t 0.726204465335 \t 0.726204465335 \t None\n",
      "macro =>  0.717380374388 \t 0.611866699539 \t 0.633120040868 \t None\n",
      "weighted =>  0.712927422533 \t 0.726204465335 \t 0.710431871304 \t None\n",
      "\n",
      "\n",
      "======================= < SVM > =======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Office\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650607128868\n",
      "[[ 71   0   0   1   0   0   0   1  13   1   0   0   0   0   0   0   5]\n",
      " [  2   0   0   7   6   0   0   0   2   4   0   0   0   0   0   0   9]\n",
      " [  1   0 131   4   0   8   1   0  11   1   0   0   0   0   0   0   6]\n",
      " [  0   0   8 205   4   1   2   0  17  61   0   0   0   0   0   0  39]\n",
      " [  1   0   4  42  64   0   5   0   6  15   0   0   0   0   0   0  25]\n",
      " [  2   0   6   0   0 186   0   0   4   0   0   0   0   0   0   0  13]\n",
      " [  0   0   6  14   1   2  96   0   3   2   0   0   0   0   0   0  20]\n",
      " [ 28   0   0   0   0   0   0 108   1   0   0   0   0   0   0   0   5]\n",
      " [  5   0   5  23   0   0   1   0 200  26   0   0   0   0   0   0  21]\n",
      " [  2   0   5 100   0   1   3   0  10  96   0   0   0   0   0   0  32]\n",
      " [  0   0  16   0   0   0   0   0   0   0   0   0   0   0   0   0   2]\n",
      " [  0   0   0  44   0   0   0   0   1   7   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   1   1   6   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0  10   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   1   0   0   0   0  20   2   0   0   0   0   0   0   7]\n",
      " [  0   0   1  16   0   0   0   0   2  36   0   0   0   0   0   0   8]\n",
      " [  0   0   6  19   2   2   1   1  14   9   0   0   0   0   0   0 504]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.77      0.70        92\n",
      "          1       0.00      0.00      0.00        30\n",
      "          2       0.70      0.80      0.75       163\n",
      "          3       0.43      0.61      0.50       337\n",
      "          4       0.81      0.40      0.53       162\n",
      "          5       0.93      0.88      0.90       211\n",
      "          6       0.77      0.67      0.71       144\n",
      "          7       0.98      0.76      0.86       142\n",
      "          8       0.66      0.71      0.68       281\n",
      "          9       0.37      0.39      0.38       249\n",
      "         10       0.00      0.00      0.00        18\n",
      "         11       0.00      0.00      0.00        53\n",
      "         12       0.00      0.00      0.00         8\n",
      "         13       0.00      0.00      0.00        12\n",
      "         14       0.00      0.00      0.00        30\n",
      "         15       0.00      0.00      0.00        63\n",
      "         16       0.72      0.90      0.80       558\n",
      "\n",
      "avg / total       0.62      0.65      0.62      2553\n",
      "\n",
      "micro =>  0.650607128868 \t 0.650607128868 \t 0.650607128868 \t None\n",
      "macro =>  0.411524458395 \t 0.405179342809 \t 0.400898314631 \t None\n",
      "weighted =>  0.616239814843 \t 0.650607128868 \t 0.623029492599 \t None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test options and evaluation metric \n",
    "# num_folds = 10\n",
    "# seed = 7 \n",
    "# scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "\"\"\" Linear Models \"\"\"\n",
    "#models.append(('Logistic Regression', LogisticRegression(penalty='l2', C=0.4)))\n",
    "#models.append(('Logistic Regression', LogisticRegression(penalty='l1', C=0.4)))\n",
    "# models.append(('Logistic Regression', LogisticRegression(solver='liblinear')))\n",
    "# models.append(('Logistic Regression', LogisticRegression(solver='newton-cg')))\n",
    "# models.append(('Logistic Regression', LogisticRegression(solver='lbfgs')))\n",
    "# models.append(('Logistic Regression', LogisticRegression(solver='sag')))\n",
    "#models.append(('Logistic Regression', LogisticRegression(solver='liblinear',penalty='l2', tol=0.00001, max_iter=100, verbose=1)))\n",
    "# models.append(('LR 1', LogisticRegression(C=10000.0, penalty='l2')))\n",
    "# models.append(('LR 2', LogisticRegression(C=0.9)))\n",
    "# models.append(('LR 2', LogisticRegression(C=0.8)))\n",
    "# models.append(('LR 2', LogisticRegression(C=0.7)))\n",
    "# models.append(('LR 2', LogisticRegression(C=0.6)))\n",
    "# models.append(('LR 3', LogisticRegression(C=0.5)))\n",
    "# models.append(('LR 3', LogisticRegression(C=0.4)))\n",
    "# models.append(('LR 3', LogisticRegression(C=0.3)))\n",
    "# models.append(('LR 3', LogisticRegression(C=0.2)))\n",
    "# models.append(('LR 4', LogisticRegression(C=10000.0, penalty='l1')))\n",
    "# models.append(('LR 5', LogisticRegression(C=100.0, penalty='l1')))\n",
    "# models.append(('LR 6', LogisticRegression(C=0.01, penalty='l1')))\n",
    "\n",
    "#models.append(('PassiveAggressiveClassifier', PassiveAggressiveClassifier(C=2000)))\n",
    "\n",
    "#models.append(('SGDClassifier', SGDClassifier(alpha = 0.00001))) # alpha = 0.0001 : default\n",
    "# 모델이 underfit이라는 것을 확인하였다. 위와 같이 l1, l2 penalty를 사용하니까 모두 성능이 떨어졌다.\n",
    "\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis())) # 진짜 오래걸림\n",
    "# models.append(('LDA', LinearDiscriminantAnalysis(tol=0.0001))) # default\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis(tol=0.1)))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis(tol=0.9))) # best?\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis(tol=1.0)))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis(tol=10)))\n",
    "\n",
    "\"\"\" Ensemble Models \"\"\"\n",
    "#models.append(('ET', ExtraTreesClassifier(n_estimators=800))) # best\n",
    "#models.append(('ET', ExtraTreesClassifier(n_estimators=100))) \n",
    "#models.append(('RF', RandomForestClassifier(n_estimators=1500))) \n",
    "#models.append(('AB', AdaBoostClassifier(n_estimators=3000))) # default: 50\n",
    "#models.append(('GBM', GradientBoostingClassifier())) # 진짜 오래걸림\n",
    "\n",
    "\"\"\" Non-linear Models \"\"\"\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('KNN', KNeighborsClassifier(n_neighbors = 7)))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('LinearSVM', LinearSVC()))\n",
    "#models.append(('SVM', SVC()))\n",
    "models.append(('SVM', SVC(C=300)))\n",
    "models.append(('SVM', SVC(C=200)))\n",
    "models.append(('SVM', SVC(C=100)))\n",
    "models.append(('SVM', SVC(C=50)))\n",
    "models.append(('SVM', SVC(C=10)))\n",
    "\"\"\" Voting Ensemble \"\"\"\n",
    "# create the sub models \n",
    "estimators = [] \n",
    "estimators.append(('logistic', LogisticRegression(penalty='l2', C=0.4) )) \n",
    "estimators.append(('et', ExtraTreesClassifier(n_estimators=800) )) \n",
    "estimators.append(('svm', SVC(C=900)))\n",
    "#estimators.append(('rf', RandomForestClassifier() )) \n",
    "#estimators.append(('cart', DecisionTreeClassifier() )) \n",
    "# create the ensemble model \n",
    "#models.append(('Voting', VotingClassifier(estimators)))  \n",
    "\n",
    "\"\"\" Neural Network \"\"\"\n",
    "#models.append(('MLP', MLPClassifier())) # \n",
    "\n",
    "\n",
    "###################\n",
    "\"\"\" Train Model \"\"\"\n",
    "###################\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, unfolded_X_train, unfolded_Y_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n",
    "\n",
    "    # just fit\n",
    "    model.fit(unfolded_X_train, unfolded_Y_train)\n",
    "    #model.fit(X_train_pca, unfolded_Y_train)\n",
    "    \n",
    "# ### COMPARE MODELS USING PLOT\n",
    "# fig = pyplot.figure() \n",
    "# fig.suptitle('Model Comparison') \n",
    "# ax = fig.add_subplot(111) \n",
    "# pyplot.boxplot(results) \n",
    "# ax.set_xticklabels(names) \n",
    "# pyplot.show()\n",
    "\n",
    "########################\n",
    "\"\"\" Evaluation Model \"\"\"\n",
    "########################\n",
    "# Make predictions on validation dataset \n",
    "# knn = KNeighborsClassifier() \n",
    "# knn.fit(X_train, Y_train) \n",
    "# predictions = knn.predict(X_validation) \n",
    "\n",
    "for name, model in models:\n",
    "    print('======================= <', name, '> =======================')\n",
    "    predictions = model.predict(unfolded_X_test)\n",
    "    #predictions = model.predict(X_test_pca)\n",
    "    print(accuracy_score(unfolded_Y_test, predictions))\n",
    "    print(confusion_matrix(unfolded_Y_test, predictions))\n",
    "    print(classification_report(unfolded_Y_test, predictions))\n",
    "    \n",
    "    pre, rec, f1, sup = (precision_recall_fscore_support(unfolded_Y_test, predictions, average='micro'))\n",
    "    print('micro => ', pre, '\\t', rec, '\\t', f1, '\\t', sup)\n",
    "    pre, rec, f1, sup = (precision_recall_fscore_support(unfolded_Y_test, predictions, average='macro'))\n",
    "    print('macro => ', pre, '\\t', rec, '\\t', f1, '\\t', sup)\n",
    "    pre, rec, f1, sup = (precision_recall_fscore_support(unfolded_Y_test, predictions, average='weighted'))\n",
    "    print('weighted => ',pre, '\\t', rec, '\\t', f1, '\\t', sup)\n",
    "    print('\\n')\n",
    "    report = classification_report(unfolded_Y_test, predictions)\n",
    "    \n",
    "#print(using_1type, using_2type, using_3type, using_4type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
