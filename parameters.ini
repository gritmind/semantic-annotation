[1_data_preparation]
val_ratio = 0.20
seed = 7

# path to save
freq_dic_path = assets/freq-dist/
lookup_table_path = assets/lookup-table/
temp_data_path = assets/temp-data/
feature_path = assets/feature-vec/

# threshold
thr_1gram = 1
thr_2gram = 2
thr_3gram = 2
thr_5gram = 1

thr_component = 1
thr_refinement_of_component = 1
thr_action = 1
thr_refinement_of_action = 1
thr_condition = 1
thr_priority = 1
thr_motivation = 1
thr_role = 1
thr_object = 1
thr_refinement_of_object = 1
thr_sub_action = 1
thr_sub_argument_of_action = 1
thr_sub_priority = 1
thr_sub_role = 1
thr_sub_object = 1
thr_sub_refinement_of_object = 1
thr_none = 1

[2_feature_extraction]

# stanford parser path
parser_jar_path = C:\\stanford-parser-full-2016-10-31\\stanford-parser.jar
model_jar_path = C:\\stanford-parser-full-2016-10-31\\stanford-parser-3.7.0-models.jar
model_path = edu\\stanford\\nlp\\models\\lexparser\\englishPCFG.ser.gz

# bag-of-n-grams
window_size_1gram = 5
window_size_class = 3

# stanford parser
window_size_pos = 9
window_size_depth = 5
window_size_n_siblings = 5 

# spaCy parser
window_size_spacy_pos = 3


[3_train_and_test]

# model hyper-parameters
LR_C = 0.1
PA_C = 2000
ET_n_estimators = 900
RF_n_estimators = 1500
KNN_n_neighbors = 7
SVM_C = 300

# neural network hyper-parameters
hidden_dim_FNN = 20
n_epoch_FNN = 10
batch_size_FNN = 64

n_epoch_CNN = 3
batch_size_CNN = 64

hidden_dim_RNN = 100
n_epoch_RNN = 3
batch_size_RNN = 128






